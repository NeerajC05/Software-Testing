{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa9eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv1D, Dropout, MaxPooling1D, BatchNormalization\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83acc22",
   "metadata": {},
   "source": [
    "Run subject_segregation.py and check-subject-validity.py prior to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcbcd0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of list: 78\n",
      "Total size of training list: 63\n",
      "Total size of testing list: 8\n",
      "Total size of validation list: 7\n",
      "List indexed correctly.\n"
     ]
    }
   ],
   "source": [
    "#Create uun list for testing, training and validation\n",
    "\n",
    "random.seed(100)\n",
    "src_folder = '../processed-data/'\n",
    "\n",
    "uun_list = [s for s in os.listdir(src_folder) if s[0]== 's']\n",
    "uun_list = random.sample(uun_list,len(uun_list))\n",
    "\n",
    "training_list = uun_list[0:63] \n",
    "testing_list = uun_list[63:71]\n",
    "validation_list = uun_list[71:]\n",
    "\n",
    "print(\"Total size of list: \" + str(len(uun_list)))\n",
    "print(\"Total size of training list: \" + str(len(training_list)))\n",
    "print(\"Total size of testing list: \" + str(len(testing_list)))\n",
    "print(\"Total size of validation list: \" + str(len(validation_list)))\n",
    "if (len(uun_list) == (len(training_list) + len(testing_list) + len(validation_list))):\n",
    "    print(\"List indexed correctly.\")\n",
    "else:\n",
    "    print(\"List indexed incorrectly. Please check the input source again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e30b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataFrame(uun_list, df_name, src_folder):\n",
    "    base_df = pd.DataFrame()\n",
    "    \n",
    "    for uun in uun_list:\n",
    "        files_per_uun = [s for s in os.listdir(os.path.join(src_folder,uun))]\n",
    "        \n",
    "        for file in files_per_uun:\n",
    "            # load data into a DataFrame \n",
    "            path = os.path.join(src_folder, uun, file)\n",
    "            new_df = pd.read_csv(path)\n",
    "            # merge into the base DataFrame \n",
    "            base_df = pd.concat([base_df, new_df])\n",
    "            \n",
    "    base_df.reset_index(drop=True, inplace=True)\n",
    "    base_df.drop(base_df[base_df['sensor_type'] == \"Thingy\"].index, inplace = True)\n",
    "    \n",
    "    print(f\"Data from: {df_name}\")\n",
    "    print(f\"The data was collected using the sensors: {base_df.sensor_type.unique()}\")\n",
    "    print(f\"The data was collected for the activities: {base_df.activity_type.unique()}\")\n",
    "    print(f\"The number of activities collected: {len(base_df.activity_type.unique())}\")\n",
    "    print(f\"The number of unique recordings is: {len(base_df.recording_id.unique())}\")\n",
    "    print(f\"The subject IDs in the recordings are: {len(base_df.subject_id.unique())}\")\n",
    "    print(\"\\n\")\n",
    "            \n",
    "    return base_df\n",
    "\n",
    "def clean_dataFrame(df):\n",
    "    df.drop('notes', axis=1, inplace=True)\n",
    "    df.drop('sensor_type', axis=1, inplace=True)\n",
    "    df.drop('subject_id', axis=1, inplace=True)\n",
    "    df.drop('activity_code', axis=1, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "def get_sliding_windows(df):\n",
    "    recording_id_list = df.recording_id.unique()\n",
    "    sliding_windows = pd.DataFrame()\n",
    "    window_size = 50 # 50 datapoints for the window size, which, at 25Hz, means 2 seconds\n",
    "    step_size = 25 # this is 50% overlap\n",
    "\n",
    "    window_number = 0 # start a counter at 0 to keep track of the window number\n",
    "\n",
    "    for recording in recording_id_list:\n",
    "        current_window = df.loc[df['recording_id'] == recording]\n",
    "        large_enough_windows = [window for window in current_window.rolling(window=window_size, min_periods=window_size) if len(window) == window_size]\n",
    "        overlapping_windows = large_enough_windows[::step_size] \n",
    "\n",
    "        for window in overlapping_windows:\n",
    "            window.loc[:, 'window_id'] = window_number\n",
    "            window_number += 1\n",
    "\n",
    "        final_sliding_windows = pd.concat(overlapping_windows)\n",
    "        sliding_windows = pd.concat([sliding_windows, final_sliding_windows])\n",
    "\n",
    "    sliding_windows.reset_index(drop=True, inplace=True)\n",
    "    return sliding_windows\n",
    "\n",
    "def model_data(df_sliding_windows):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for window_id, group in df_sliding_windows.groupby('window_id'):\n",
    "        print(f\"window_id = {window_id}\")\n",
    "\n",
    "        shape = group[columns_of_interest].values.shape\n",
    "        print(f\"shape = {shape}\")\n",
    "        \n",
    "        X.append(group[columns_of_interest].values)\n",
    "        y.append(class_labels[group[\"activity_type\"].values[0]])\n",
    "        \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(pd.get_dummies(np.asarray(y)), dtype=np.float32)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a19ed662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: Training DF\n",
      "The data was collected using the sensors: ['Respeck']\n",
      "The data was collected for the activities: ['Walking at normal speed' 'Descending stairs' 'Lying down on back'\n",
      " 'Sitting bent backward' 'Lying down right' 'Movement'\n",
      " 'Sitting bent forward' 'Climbing stairs' 'Standing' 'Desk work' 'Sitting'\n",
      " 'Lying down left' 'Lying down on stomach' 'Running']\n",
      "The number of activities collected: 14\n",
      "The number of unique recordings is: 882\n",
      "The subject IDs in the recordings are: 64\n",
      "\n",
      "\n",
      "Data from: Testing DF\n",
      "The data was collected using the sensors: ['Respeck']\n",
      "The data was collected for the activities: ['Climbing stairs' 'Sitting bent backward' 'Lying down left'\n",
      " 'Walking at normal speed' 'Lying down on back' 'Movement'\n",
      " 'Lying down on stomach' 'Running' 'Lying down right'\n",
      " 'Sitting bent forward' 'Desk work' 'Sitting' 'Descending stairs'\n",
      " 'Standing']\n",
      "The number of activities collected: 14\n",
      "The number of unique recordings is: 112\n",
      "The subject IDs in the recordings are: 8\n",
      "\n",
      "\n",
      "Data from: Validation DF\n",
      "The data was collected using the sensors: ['Respeck']\n",
      "The data was collected for the activities: ['Sitting' 'Lying down left' 'Lying down on back' 'Standing'\n",
      " 'Sitting bent forward' 'Walking at normal speed' 'Lying down on stomach'\n",
      " 'Lying down right' 'Movement' 'Sitting bent backward' 'Desk work'\n",
      " 'Running' 'Climbing stairs' 'Descending stairs']\n",
      "The number of activities collected: 14\n",
      "The number of unique recordings is: 97\n",
      "The subject IDs in the recordings are: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df = create_dataFrame(training_list, \"Training DF\", src_folder)\n",
    "testing_df = create_dataFrame(testing_list, \"Testing DF\", src_folder)\n",
    "validation_df = create_dataFrame(validation_list, \"Validation DF\", src_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5862902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataFrame(training_df)\n",
    "clean_dataFrame(testing_df)\n",
    "clean_dataFrame(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.drop(training_df[training_df['activity_type'] == \"Climbing stairs\"].index, inplace = True)\n",
    "training_df.drop(training_df[training_df['activity_type'] == \"Descending stairs\"].index, inplace = True)\n",
    "training_df.drop(training_df[training_df['activity_type'] == \"Movement\"].index, inplace = True)\n",
    "\n",
    "testing_df.drop(testing_df[testing_df['activity_type'] == \"Climbing stairs\"].index, inplace = True)\n",
    "testing_df.drop(testing_df[testing_df['activity_type'] == \"Descending stairs\"].index, inplace = True)\n",
    "testing_df.drop(testing_df[testing_df['activity_type'] == \"Movement\"].index, inplace = True)\n",
    "\n",
    "validation_df.drop(validation_df[validation_df['activity_type'] == \"Climbing stairs\"].index, inplace = True)\n",
    "validation_df.drop(validation_df[validation_df['activity_type'] == \"Descending stairs\"].index, inplace = True)\n",
    "validation_df.drop(validation_df[validation_df['activity_type'] == \"Movement\"].index, inplace = True)\n",
    "\n",
    "\n",
    "training_df['activity_type'] = training_df['activity_type'].replace(['Sitting', 'Sitting bent forward', 'Sitting bent backward', 'Standing', 'Desk work'], 'Sitting/Standing')\n",
    "testing_df['activity_type'] = testing_df['activity_type'].replace(['Sitting', 'Sitting bent forward', 'Sitting bent backward', 'Standing', 'Desk work'], 'Sitting/Standing')\n",
    "validation_df['activity_type'] = validation_df['activity_type'].replace(['Sitting', 'Sitting bent forward', 'Sitting bent backward', 'Standing', 'Desk work'], 'Sitting/Standing')\n",
    "\n",
    "training_df['activity_type'] = training_df['activity_type'].replace(['Lying down right', 'Lying down left', 'Lying down on back', 'Lying down on stomach'], 'Lying down')\n",
    "testing_df['activity_type'] = testing_df['activity_type'].replace(['Lying down right', 'Lying down left', 'Lying down on back', 'Lying down on stomach'], 'Lying down')\n",
    "validation_df['activity_type'] = validation_df['activity_type'].replace(['Lying down right', 'Lying down left', 'Lying down on back', 'Lying down on stomach'], 'Lying down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1cbf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "class_labels = {\n",
    "    'Sitting/Standing' : 0,\n",
    "    'Walking at normal speed' : 1,\n",
    "    'Lying down' : 2,\n",
    "    'Running' : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cf5a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_id = 0\n",
      "shape = (50, 6)\n",
      "window_id = 1\n",
      "shape = (50, 6)\n",
      "window_id = 2\n",
      "shape = (50, 6)\n",
      "window_id = 3\n",
      "shape = (50, 6)\n",
      "window_id = 4\n",
      "shape = (50, 6)\n",
      "window_id = 5\n",
      "shape = (50, 6)\n",
      "window_id = 6\n",
      "shape = (50, 6)\n",
      "window_id = 7\n",
      "shape = (50, 6)\n",
      "window_id = 8\n",
      "shape = (50, 6)\n",
      "window_id = 9\n",
      "shape = (50, 6)\n",
      "window_id = 10\n",
      "shape = (50, 6)\n",
      "window_id = 11\n",
      "shape = (50, 6)\n",
      "window_id = 12\n",
      "shape = (50, 6)\n",
      "window_id = 13\n",
      "shape = (50, 6)\n",
      "window_id = 14\n",
      "shape = (50, 6)\n",
      "window_id = 15\n",
      "shape = (50, 6)\n",
      "window_id = 16\n",
      "shape = (50, 6)\n",
      "window_id = 17\n",
      "shape = (50, 6)\n",
      "window_id = 18\n",
      "shape = (50, 6)\n",
      "window_id = 19\n",
      "shape = (50, 6)\n",
      "window_id = 20\n",
      "shape = (50, 6)\n",
      "window_id = 21\n",
      "shape = (50, 6)\n",
      "window_id = 22\n",
      "shape = (50, 6)\n",
      "window_id = 23\n",
      "shape = (50, 6)\n",
      "window_id = 24\n",
      "shape = (50, 6)\n",
      "window_id = 25\n",
      "shape = (50, 6)\n",
      "window_id = 26\n",
      "shape = (50, 6)\n",
      "window_id = 27\n",
      "shape = (50, 6)\n",
      "window_id = 28\n",
      "shape = (50, 6)\n",
      "window_id = 29\n",
      "shape = (50, 6)\n",
      "window_id = 30\n",
      "shape = (50, 6)\n",
      "window_id = 31\n",
      "shape = (50, 6)\n",
      "window_id = 32\n",
      "shape = (50, 6)\n",
      "window_id = 33\n",
      "shape = (50, 6)\n",
      "window_id = 34\n",
      "shape = (50, 6)\n",
      "window_id = 35\n",
      "shape = (50, 6)\n",
      "window_id = 36\n",
      "shape = (50, 6)\n",
      "window_id = 37\n",
      "shape = (50, 6)\n",
      "window_id = 38\n",
      "shape = (50, 6)\n",
      "window_id = 39\n",
      "shape = (50, 6)\n",
      "window_id = 40\n",
      "shape = (50, 6)\n",
      "window_id = 41\n",
      "shape = (50, 6)\n",
      "window_id = 42\n",
      "shape = (50, 6)\n",
      "window_id = 43\n",
      "shape = (50, 6)\n",
      "window_id = 44\n",
      "shape = (50, 6)\n",
      "window_id = 45\n",
      "shape = (50, 6)\n",
      "window_id = 46\n",
      "shape = (50, 6)\n",
      "window_id = 47\n",
      "shape = (50, 6)\n",
      "window_id = 48\n",
      "shape = (50, 6)\n",
      "window_id = 49\n",
      "shape = (50, 6)\n",
      "window_id = 50\n",
      "shape = (50, 6)\n",
      "window_id = 51\n",
      "shape = (50, 6)\n",
      "window_id = 52\n",
      "shape = (50, 6)\n",
      "window_id = 53\n",
      "shape = (50, 6)\n",
      "window_id = 54\n",
      "shape = (50, 6)\n",
      "window_id = 55\n",
      "shape = (50, 6)\n",
      "window_id = 56\n",
      "shape = (50, 6)\n",
      "window_id = 57\n",
      "shape = (50, 6)\n",
      "window_id = 58\n",
      "shape = (50, 6)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sitting / Standing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/sp7hbb713f7b8wzpdh_c9sb40000gn/T/ipykernel_87051/2330509043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_sliding_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sliding_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_sliding_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_sliding_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_sliding_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bj/sp7hbb713f7b8wzpdh_c9sb40000gn/T/ipykernel_87051/3335770407.py\u001b[0m in \u001b[0;36mmodel_data\u001b[0;34m(df_sliding_windows)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_of_interest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"activity_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sitting / Standing'"
     ]
    }
   ],
   "source": [
    "training_sliding_windows = get_sliding_windows(training_df)\n",
    "testing_sliding_windows = get_sliding_windows(testing_df)\n",
    "validation_sliding_windows = get_sliding_windows(validation_df)\n",
    "\n",
    "(X_train, y_train) = model_data(training_sliding_windows)\n",
    "(X_test, y_test) = model_data(testing_sliding_windows)\n",
    "(X_validate, y_validate) = model_data(validation_sliding_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d6be6",
   "metadata": {},
   "source": [
    "CNN Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 64\n",
    "kernel_size = 3\n",
    "n_features = 6\n",
    "activation='relu'\n",
    "n_classes = 4\n",
    "window_size = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='linear', \n",
    "                 input_shape=(window_size, n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation))\n",
    "\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation))\n",
    "\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation))\n",
    "\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='linear'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbae339",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,accuracy) = model.evaluate(X_test, y_test)\n",
    "accuracy = accuracy * 100.0\n",
    "print(accuracy)\n",
    "\n",
    "y_pred_ohe = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Classification report\")\n",
    "print(\"*\" * 80)\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true_labels, y_pred_labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,accuracy) = model.evaluate(X_validate, y_validate)\n",
    "accuracy = accuracy * 100.0\n",
    "print(accuracy)\n",
    "\n",
    "y_pred_ohe = model.predict(X_validate)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "y_true_labels = np.argmax(y_validate, axis=1)\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Classification report\")\n",
    "print(\"*\" * 80)\n",
    "print(classification_report(y_true_labels, y_pred_labels))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true_labels, y_pred_labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file = \"linear.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tfmodel = converter.convert()\n",
    "open(\"EssentialFeatures.tflite\",\"wb\").write(tfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc877ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
